"""
Avatar Lipsync Web Application
–í–µ–±-—Å–µ—Ä–≤–∏—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞ —á–µ—Ä–µ–∑ TTS –∏ Wav2Lip
–î–µ—Ä–∂–∏—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
"""
import os
import sys
import time
import subprocess
import io
from pathlib import Path
from datetime import datetime
import requests
import shutil

from flask import Flask, request, jsonify, send_file, render_template
from flask_cors import CORS
import torch
import torchaudio
import torchaudio.functional as audio_fn
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ modern-lipsync
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'modern-lipsync'))

from service import LipsyncService

app = Flask(__name__)
CORS(app)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
@app.before_request
def log_request_info():
    logger.info('='*80)
    logger.info(f'üì® –í—Ö–æ–¥—è—â–∏–π –∑–∞–ø—Ä–æ—Å:')
    logger.info(f'   –ú–µ—Ç–æ–¥: {request.method}')
    logger.info(f'   URL: {request.url}')
    logger.info(f'   Path: {request.path}')
    logger.info(f'   Remote IP: {request.remote_addr}')
    logger.info(f'   Headers:')
    for header, value in request.headers:
        logger.info(f'      {header}: {value}')
    if request.method in ['POST', 'PUT', 'PATCH']:
        logger.info(f'   Body: {request.get_data(as_text=True)[:500]}...')
    logger.info('='*80)

@app.after_request
def log_response_info(response):
    logger.info(f'üì§ –û—Ç–≤–µ—Ç: {response.status_code}')
    return response

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
AVATAR_IMAGE = '/workspace/avatar.jpg'
CHECKPOINT_PATH = '/workspace/Wav2Lip-SD-GAN.pt'
CHECKPOINT_PATH_NOGAN = '/workspace/Wav2Lip-SD-NOGAN.pt'  # –î–ª—è realtime2
TTS_API_URL = 'https://tts.sk-ai.kz/api/tts'
OUTPUT_DIR = '/workspace/outputs'
TEMP_DIR = '/workspace/temp_web'

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(TEMP_DIR, exist_ok=True)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã —Å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
lipsync_service = None  # GAN –º–æ–¥–µ–ª—å (–¥–ª—è realtime)
lipsync_service_nogan = None  # NOGAN –º–æ–¥–µ–ª—å (–¥–ª—è realtime2)
avatar_preloaded = None


def init_service():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ —Å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π –∏ –∞–≤–∞—Ç–∞—Ä–∞"""
    global lipsync_service, lipsync_service_nogan, avatar_preloaded
    
    print("\n" + "="*60)
    print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Avatar Lipsync Service")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤
    if not os.path.exists(AVATAR_IMAGE):
        raise FileNotFoundError(f"–ê–≤–∞—Ç–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {AVATAR_IMAGE}")
    
    if not os.path.exists(CHECKPOINT_PATH):
        raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å GAN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {CHECKPOINT_PATH}")
    
    if not os.path.exists(CHECKPOINT_PATH_NOGAN):
        raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å NOGAN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {CHECKPOINT_PATH_NOGAN}")
    
    print(f"‚úÖ –ê–≤–∞—Ç–∞—Ä –Ω–∞–π–¥–µ–Ω: {AVATAR_IMAGE}")
    print(f"‚úÖ –ú–æ–¥–µ–ª—å GAN –Ω–∞–π–¥–µ–Ω–∞: {CHECKPOINT_PATH}")
    print(f"‚úÖ –ú–æ–¥–µ–ª—å NOGAN –Ω–∞–π–¥–µ–Ω–∞: {CHECKPOINT_PATH_NOGAN}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    if device == 'cuda':
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True
        if hasattr(torch, 'set_float32_matmul_precision'):
            torch.set_float32_matmul_precision('high')
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º GAN —Å–µ—Ä–≤–∏—Å (–¥–ª—è realtime)
    print("\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ GAN –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç—å...")
    start = time.time()
    
    lipsync_service = LipsyncService(
        checkpoint_path=CHECKPOINT_PATH,
        device=device,
        face_det_batch_size=16,
        wav2lip_batch_size=128
    )
    model_ready_time = time.time()
    print(f"‚úÖ GAN –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {model_ready_time - start:.2f}s")
    
    # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—á–Ω–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞ (—É—Å–∫–æ—Ä—è–µ—Ç /realtime)
    preload_start = time.time()
    lipsync_service.preload_static_face(
        face_path=AVATAR_IMAGE,
        fps=25.0,
        pads=(0, 50, 0, 0)
    )
    print(f"‚ö° –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞ (GAN) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - preload_start:.2f}s")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º NOGAN —Å–µ—Ä–≤–∏—Å (–¥–ª—è realtime2)
    print("\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ NOGAN –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç—å...")
    start = time.time()
    
    lipsync_service_nogan = LipsyncService(
        checkpoint_path=CHECKPOINT_PATH_NOGAN,
        device=device,
        face_det_batch_size=16,
        wav2lip_batch_size=128
    )
    model_ready_time = time.time()
    print(f"‚úÖ NOGAN –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {model_ready_time - start:.2f}s")
    
    # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è NOGAN
    preload_start = time.time()
    lipsync_service_nogan.preload_static_face(
        face_path=AVATAR_IMAGE,
        fps=25.0,
        pads=(0, 50, 0, 0)
    )
    print(f"‚ö° –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞ (NOGAN) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - preload_start:.2f}s")
    
    # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞ –≤ –ø–∞–º—è—Ç—å
    print(f"\nüñºÔ∏è  –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞...")
    import cv2
    avatar_preloaded = cv2.imread(AVATAR_IMAGE)
    print(f"‚úÖ –ê–≤–∞—Ç–∞—Ä –∑–∞–≥—Ä—É–∂–µ–Ω: {avatar_preloaded.shape}")
    
    print("\n" + "="*60)
    print("‚úÖ –°–µ—Ä–≤–∏—Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    print("="*60 + "\n")


def generate_tts(text: str, language: str = 'ru') -> bytes:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS —á–µ—Ä–µ–∑ API
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏
        language: –Ø–∑—ã–∫ (ru, kk, en)
        
    Returns:
        –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP3
    """
    print(f"üé§ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS...")
    print(f"   –¢–µ–∫—Å—Ç: {text[:50]}{'...' if len(text) > 50 else ''}")
    print(f"   –Ø–∑—ã–∫: {language}")
    
    try:
        response = requests.post(
            TTS_API_URL,
            json={'text': text, 'lang': language},
            timeout=30
        )
        response.raise_for_status()
        
        audio_data = response.content
        print(f"‚úÖ TTS —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {len(audio_data) / 1024:.2f} KB")
        return audio_data
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ TTS: {e}")
        raise


def convert_to_wav(mp3_data: bytes, output_path: str):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è MP3 –≤ WAV 16kHz mono –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤"""
    print(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV...")
    
    audio_buffer = io.BytesIO(mp3_data)
    waveform = None
    sample_rate = None
    target_sr = 16000
    
    try:
        waveform, sample_rate = torchaudio.load(audio_buffer, format='mp3')
        waveform = waveform.float()
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)
        if sample_rate != target_sr:
            waveform = audio_fn.resample(waveform, sample_rate, target_sr)
            sample_rate = target_sr
        
        torchaudio.save(output_path, waveform.cpu(), sample_rate)
        print(f"‚úÖ WAV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        return waveform, sample_rate
    except Exception as decode_error:
        print(f"‚ö†Ô∏è torchaudio –Ω–µ —Å–º–æ–≥ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å MP3 ({decode_error}); fallback –Ω–∞ ffmpeg.")
        
        temp_mp3 = os.path.join(TEMP_DIR, f'temp_{int(time.time())}.mp3')
        with open(temp_mp3, 'wb') as f:
            f.write(mp3_data)
        
        cmd = [
            'ffmpeg', '-y', '-i', temp_mp3,
            '-ar', str(target_sr),
            '-ac', '1',
            '-f', 'wav',
            '-acodec', 'pcm_s16le',
            output_path,
            '-loglevel', 'error'
        ]
        subprocess.run(cmd, check=True)
        os.remove(temp_mp3)
        
        waveform, sample_rate = torchaudio.load(output_path)
        waveform = waveform.float()
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)
        print(f"‚úÖ WAV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        return waveform, sample_rate


@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ - —Å–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ"""
    return render_template('index.html')


@app.route('/realtime')
def realtime():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–∞–ª—Ç–∞–π–º –æ–∑–≤—É—á–∫–∏ (GAN –º–æ–¥–µ–ª—å)"""
    return render_template('realtime.html')


@app.route('/realtime2')
def realtime2():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–∞–ª—Ç–∞–π–º –æ–∑–≤—É—á–∫–∏ (NOGAN –º–æ–¥–µ–ª—å - –ª—É—á—à–µ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –±–µ–∑ –∑—É–±–æ–≤)"""
    return render_template('realtime2.html')


@app.route('/realtime3')
def realtime3():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–∞–ª—Ç–∞–π–º –æ–∑–≤—É—á–∫–∏ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è)"""
    return render_template('realtime3.html')


@app.route('/api-test')
def api_test():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
    return render_template('api_test.html')


@app.route('/test-long')
def test_long():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    return send_file('/workspace/test_long_text.html')


@app.route('/api/health')
@app.route('/r/api/health')  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
    return jsonify({
        'status': 'ready',
        'models_loaded': lipsync_service is not None,
        'avatar_loaded': avatar_preloaded is not None,
        'device': 'cuda' if torch.cuda.is_available() else 'cpu'
    })


@app.route('/api/generate', methods=['POST'])
@app.route('/r/api/generate', methods=['POST'])  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def generate_avatar_speech():
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞
    
    POST /api/generate
    {
        "text": "–¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏",
        "language": "ru"  // –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ru
    }
    
    Returns:
        Video file (MP4) —Å –≥–æ–≤–æ—Ä—è—â–∏–º –∞–≤–∞—Ç–∞—Ä–æ–º
    """
    try:
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({'error': '–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–µ "text"'}), 400
        
        text = data['text'].strip()
        language = data.get('language', 'ru')
        
        if not text:
            return jsonify({'error': '–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'}), 400
        
        if language not in ['ru', 'kk', 'en']:
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —è–∑—ã–∫'}), 400
        
        print("\n" + "="*60)
        print(f"üé¨ –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        print("="*60)
        print(f"–¢–µ–∫—Å—Ç: {text}")
        print(f"–Ø–∑—ã–∫: {language}")
        
        start_total = time.time()
        
        # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS
        start = time.time()
        audio_data = generate_tts(text, language)
        tts_time = time.time() - start
        
        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        audio_path = os.path.join(TEMP_DIR, f'audio_{timestamp}.wav')
        
        start = time.time()
        audio_waveform, audio_sample_rate = convert_to_wav(audio_data, audio_path)
        convert_time = time.time() - start
        
        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è lip-sync (–º–æ–¥–µ–ª–∏ —É–∂–µ –≤ –ø–∞–º—è—Ç–∏!)
        output_path = os.path.join(OUTPUT_DIR, f'avatar_{timestamp}.mp4')
        
        print(f"\nüé≠ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è lip-sync...")
        start = time.time()
        
        stats = lipsync_service.process(
            face_path=AVATAR_IMAGE,
            audio_path=audio_path,
            output_path=output_path,
            static=True,  # –°—Ç–∞—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            pads=(0, 50, 0, 0),
            fps=25.0,
            audio_waveform=audio_waveform,
            audio_sample_rate=audio_sample_rate
        )
        
        lipsync_time = time.time() - start
        total_time = time.time() - start_total
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if os.path.exists(audio_path):
            os.remove(audio_path)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   TTS –≥–µ–Ω–µ—Ä–∞—Ü–∏—è:    {tts_time:.2f}s")
        print(f"   –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è:      {convert_time:.2f}s")
        print(f"   Lip-sync:         {lipsync_time:.2f}s")
        print(f"     - –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ:   {stats['load_video_time']:.2f}s")
        print(f"     - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ:  {stats['process_audio_time']:.2f}s")
        print(f"     - –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü–∞:    {stats['face_detection_time']:.2f}s")
        print(f"     - –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏:  {stats['inference_time']:.2f}s")
        print(f"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        print(f"   –ò–¢–û–ì–û:            {total_time:.2f}s")
        print(f"\n‚úÖ –í–∏–¥–µ–æ –≥–æ—Ç–æ–≤–æ: {output_path}")
        print("="*60 + "\n")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ —Ñ–∞–π–ª
        return send_file(
            output_path,
            mimetype='video/mp4',
            as_attachment=True,
            download_name=f'avatar_speech.mp4'
        )
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/avatar')
@app.route('/r/api/avatar')  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def get_avatar():
    """–ü–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞–≤–∞—Ç–∞—Ä–∞"""
    return send_file(AVATAR_IMAGE, mimetype='image/jpeg')


@app.route('/api/generate_stream', methods=['POST'])
@app.route('/r/api/generate_stream', methods=['POST'])  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def generate_stream_chunk():
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ-—á–∞–Ω–∫–∞ —Å lip-sync –¥–ª—è —Ä–µ–∞–ª—Ç–∞–π–º –æ–∑–≤—É—á–∫–∏
    –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
    
    POST /api/generate_stream
    {
        "text": "–¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞",
        "language": "ru",
        "chunk_index": 0
    }
    
    Returns:
        Video file (MP4) - —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –≥—É–±
    """
    try:
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({'error': '–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–µ "text"'}), 400
        
        text = data['text'].strip()
        language = data.get('language', 'ru')
        chunk_index = data.get('chunk_index', 0)
        
        if not text:
            return jsonify({'error': '–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'}), 400
        
        print(f"\nÔøΩ –†–µ–∞–ª—Ç–∞–π–º —á–∞–Ω–∫ #{chunk_index}: {text[:50]}...")
        start_total = time.time()
        
        # 1. TTS –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        start = time.time()
        audio_data = generate_tts(text, language)
        tts_time = time.time() - start
        
        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        audio_path = os.path.join(TEMP_DIR, f'chunk_{chunk_index}_{timestamp}.wav')
        
        start = time.time()
        audio_waveform, audio_sample_rate = convert_to_wav(audio_data, audio_path)
        convert_time = time.time() - start
        
        # 3. –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è lip-sync
        output_path = os.path.join(OUTPUT_DIR, f'chunk_{chunk_index}_{timestamp}.mp4')
        
        start = time.time()
        stats = lipsync_service.process(
            face_path=AVATAR_IMAGE,
            audio_path=audio_path,
            output_path=output_path,
            static=True,
            pads=(0, 50, 0, 0),
            fps=25.0,
            audio_waveform=audio_waveform,
            audio_sample_rate=audio_sample_rate
        )
        lipsync_time = time.time() - start
        total_time = time.time() - start_total
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if os.path.exists(audio_path):
            os.remove(audio_path)
        
        print(f"‚úÖ –ß–∞–Ω–∫ #{chunk_index} –≥–æ—Ç–æ–≤ –∑–∞ {total_time:.2f}s (TTS: {tts_time:.2f}s, Sync: {lipsync_time:.2f}s)")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ
        return send_file(
            output_path,
            mimetype='video/mp4',
            as_attachment=False,
            download_name=f'chunk_{chunk_index}.mp4'
        )
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ stream: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/generate_stream_nogan', methods=['POST'])
@app.route('/r/api/generate_stream_nogan', methods=['POST'])  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def generate_stream_chunk_nogan():
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ-—á–∞–Ω–∫–∞ —Å lip-sync –¥–ª—è —Ä–µ–∞–ª—Ç–∞–π–º –æ–∑–≤—É—á–∫–∏ (GAN –º–æ–¥–µ–ª—å —Å –∑—É–±–∞–º–∏)
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç GAN –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑—É–±–æ–≤
    
    POST /api/generate_stream_nogan
    {
        "text": "–¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞",
        "language": "ru",
        "chunk_index": 0
    }
    
    Returns:
        Video file (MP4) - —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –≥—É–± (GAN - —Å –∑—É–±–∞–º–∏)
    """
    try:
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({'error': '–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–µ "text"'}), 400
        
        text = data['text'].strip()
        language = data.get('language', 'ru')
        chunk_index = data.get('chunk_index', 0)
        
        if not text:
            return jsonify({'error': '–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'}), 400
        
        print(f"\nü¶∑ –†–µ–∞–ª—Ç–∞–π–º2 (GAN —Å –∑—É–±–∞–º–∏) —á–∞–Ω–∫ #{chunk_index}: {text[:50]}...")
        start_total = time.time()
        
        # 1. TTS –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        start = time.time()
        audio_data = generate_tts(text, language)
        tts_time = time.time() - start
        
        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        audio_path = os.path.join(TEMP_DIR, f'chunk_gan2_{chunk_index}_{timestamp}.wav')
        
        start = time.time()
        audio_waveform, audio_sample_rate = convert_to_wav(audio_data, audio_path)
        convert_time = time.time() - start
        
        # 3. –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è lip-sync —Å GAN –º–æ–¥–µ–ª—å—é (–±—É–¥—É—Ç –∑—É–±—ã!)
        output_path = os.path.join(OUTPUT_DIR, f'chunk_gan2_{chunk_index}_{timestamp}.mp4')
        
        start = time.time()
        stats = lipsync_service.process(  # ‚Üê –ò—Å–ø–æ–ª—å–∑—É–µ–º GAN –≤–º–µ—Å—Ç–æ NOGAN!
            face_path=AVATAR_IMAGE,
            audio_path=audio_path,
            output_path=output_path,
            static=True,
            pads=(0, 50, 0, 0),
            fps=25.0,
            audio_waveform=audio_waveform,
            audio_sample_rate=audio_sample_rate
        )
        lipsync_time = time.time() - start
        total_time = time.time() - start_total
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if os.path.exists(audio_path):
            os.remove(audio_path)
        
        print(f"‚úÖ GAN —á–∞–Ω–∫ #{chunk_index} –≥–æ—Ç–æ–≤ –∑–∞ {total_time:.2f}s (TTS: {tts_time:.2f}s, Sync: {lipsync_time:.2f}s)")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ
        return send_file(
            output_path,
            mimetype='video/mp4',
            as_attachment=False,
            download_name=f'chunk_gan2_{chunk_index}.mp4'
        )
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ stream GAN: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/generate_stream_custom', methods=['POST'])
@app.route('/r/api/generate_stream_custom', methods=['POST'])
def generate_stream_chunk_custom():
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ-—á–∞–Ω–∫–∞ —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    POST /api/generate_stream_custom
    {
        "text": "–¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞",
        "language": "ru",
        "chunk_index": 0,
        "model": "gan" –∏–ª–∏ "nogan",
        "pad_top": 0,
        "pad_bottom": 10,
        "pad_left": 0,
        "pad_right": 0
    }
    
    Returns:
        Video file (MP4) - —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –≥—É–±
    """
    try:
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({'error': '–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–µ "text"'}), 400
        
        text = data['text'].strip()
        language = data.get('language', 'ru')
        chunk_index = data.get('chunk_index', 0)
        model_type = data.get('model', 'gan')  # gan –∏–ª–∏ nogan
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã padding
        pad_top = data.get('pad_top', 0)
        pad_bottom = data.get('pad_bottom', 50)
        pad_left = data.get('pad_left', 0)
        pad_right = data.get('pad_right', 0)
        
        if not text:
            return jsonify({'error': '–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'}), 400
        
        print(f"\nüéõÔ∏è –ö–∞—Å—Ç–æ–º–Ω—ã–π —á–∞–Ω–∫ #{chunk_index} ({model_type.upper()}):")
        print(f"   Pads: top={pad_top}, bottom={pad_bottom}, left={pad_left}, right={pad_right}")
        print(f"   –¢–µ–∫—Å—Ç: {text[:50]}...")
        
        start_total = time.time()
        
        # 1. TTS –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        start = time.time()
        audio_data = generate_tts(text, language)
        tts_time = time.time() - start
        
        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        audio_path = os.path.join(TEMP_DIR, f'chunk_custom_{chunk_index}_{timestamp}.wav')
        
        start = time.time()
        audio_waveform, audio_sample_rate = convert_to_wav(audio_data, audio_path)
        convert_time = time.time() - start
        
        # 3. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        service = lipsync_service if model_type == 'gan' else lipsync_service_nogan
        
        # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è lip-sync —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        output_path = os.path.join(OUTPUT_DIR, f'chunk_custom_{chunk_index}_{timestamp}.mp4')
        
        start = time.time()
        stats = service.process(
            face_path=AVATAR_IMAGE,
            audio_path=audio_path,
            output_path=output_path,
            static=True,
            pads=(pad_top, pad_bottom, pad_left, pad_right),  # –ö–∞—Å—Ç–æ–º–Ω—ã–µ padding!
            fps=25.0,
            audio_waveform=audio_waveform,
            audio_sample_rate=audio_sample_rate
        )
        lipsync_time = time.time() - start
        total_time = time.time() - start_total
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if os.path.exists(audio_path):
            os.remove(audio_path)
        
        print(f"‚úÖ –ö–∞—Å—Ç–æ–º —á–∞–Ω–∫ #{chunk_index} –≥–æ—Ç–æ–≤ –∑–∞ {total_time:.2f}s")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ
        return send_file(
            output_path,
            mimetype='video/mp4',
            as_attachment=False,
            download_name=f'chunk_custom_{chunk_index}.mp4'
        )
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ custom stream: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/stream_chunks', methods=['POST'])
@app.route('/r/api/stream_chunks', methods=['POST'])  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def stream_chunks():
    """
    API –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ —á–∞–Ω–∫–∞–º–∏ (–¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –¥—Ä—É–≥–∏–º–∏ —Å–∞–π—Ç–∞–º–∏)
    
    POST /api/stream_chunks
    {
        "text": "–î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏",
        "language": "ru",  // –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ru
        "chunk_size": 15   // –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —á–∞–Ω–∫–µ
    }
    
    Returns:
        JSON —Å –º–∞—Å—Å–∏–≤–æ–º —á–∞–Ω–∫–æ–≤:
        {
            "total_chunks": 5,
            "chunks": [
                {
                    "index": 0,
                    "text": "–¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞",
                    "video_url": "/api/chunk/video/abc123",
                    "audio_url": "/api/chunk/audio/abc123",
                    "duration": 3.5
                },
                ...
            ]
        }
    """
    try:
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({'error': '–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–µ "text"'}), 400
        
        text = data['text'].strip()
        language = data.get('language', 'ru')
        chunk_size = data.get('chunk_size', 15)  # —Å–ª–æ–≤ –≤ —á–∞–Ω–∫–µ
        
        if not text:
            return jsonify({'error': '–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'}), 400
        
        if language not in ['ru', 'kk', 'en']:
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —è–∑—ã–∫'}), 400
        
        print(f"\nüé¨ API Stream Chunks: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, —è–∑—ã–∫: {language}")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏
        words = text.split()
        text_chunks = []
        for i in range(0, len(words), chunk_size):
            chunk_text = ' '.join(words[i:i + chunk_size])
            text_chunks.append(chunk_text)
        
        print(f"üìù –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(text_chunks)} —á–∞–Ω–∫–æ–≤")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ —á–∞–Ω–∫–∏
        chunks_info = []
        
        for idx, chunk_text in enumerate(text_chunks):
            print(f"\nüé§ –ß–∞–Ω–∫ {idx+1}/{len(text_chunks)}: {chunk_text[:50]}...")
            
            try:
                # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS
                audio_data = generate_tts(chunk_text, language)
                
                # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                chunk_id = f"{timestamp}_{idx}"
                audio_path = os.path.join(TEMP_DIR, f'chunk_audio_{chunk_id}.wav')
                audio_waveform, audio_sample_rate = convert_to_wav(audio_data, audio_path)
                
                # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å lip-sync
                video_path = os.path.join(OUTPUT_DIR, f'chunk_video_{chunk_id}.mp4')
                stats = lipsync_service.process(
                    face_path=AVATAR_IMAGE,
                    audio_path=audio_path,
                    output_path=video_path,
                    static=True,
                    pads=(0, 50, 0, 0),
                    fps=25.0,
                    audio_waveform=audio_waveform,
                    audio_sample_rate=audio_sample_rate
                )
                
                # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
                duration = round(audio_waveform.shape[1] / audio_sample_rate, 2)
                
                # –ö–æ–ø–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ outputs –¥–ª—è –¥–æ—Å—Ç—É–ø–∞
                audio_output_path = os.path.join(OUTPUT_DIR, f'chunk_audio_{chunk_id}.wav')
                shutil.copy(audio_path, audio_output_path)
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                os.remove(audio_path)
                
                chunks_info.append({
                    'index': idx,
                    'text': chunk_text,
                    'video_url': f'/api/chunk/video/{chunk_id}',
                    'audio_url': f'/api/chunk/audio/{chunk_id}',
                    'duration': duration
                })
                
                print(f"‚úÖ –ß–∞–Ω–∫ {idx+1} –≥–æ—Ç–æ–≤ ({duration:.2f}s)")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —á–∞–Ω–∫–∞ {idx}: {e}")
                chunks_info.append({
                    'index': idx,
                    'text': chunk_text,
                    'error': str(e)
                })
        
        print(f"\n‚úÖ –í—Å–µ —á–∞–Ω–∫–∏ –≥–æ—Ç–æ–≤—ã: {len(chunks_info)}")
        
        return jsonify({
            'success': True,
            'total_chunks': len(chunks_info),
            'chunks': chunks_info,
            'language': language
        })
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ API: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/chunk/video/<chunk_id>')
@app.route('/r/api/chunk/video/<chunk_id>')  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def get_chunk_video(chunk_id):
    """–ü–æ–ª—É—á–∏—Ç—å –≤–∏–¥–µ–æ —á–∞–Ω–∫ –ø–æ ID"""
    try:
        video_path = os.path.join(OUTPUT_DIR, f'chunk_video_{chunk_id}.mp4')
        if not os.path.exists(video_path):
            return jsonify({'error': '–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}), 404
        
        return send_file(
            video_path,
            mimetype='video/mp4',
            as_attachment=False
        )
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/chunk/audio/<chunk_id>')
@app.route('/r/api/chunk/audio/<chunk_id>')  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def get_chunk_audio(chunk_id):
    """–ü–æ–ª—É—á–∏—Ç—å –∞—É–¥–∏–æ —á–∞–Ω–∫ –ø–æ ID"""
    try:
        audio_path = os.path.join(OUTPUT_DIR, f'chunk_audio_{chunk_id}.wav')
        if not os.path.exists(audio_path):
            return jsonify({'error': '–ê—É–¥–∏–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}), 404
        
        return send_file(
            audio_path,
            mimetype='audio/wav',
            as_attachment=False
        )
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/cleanup', methods=['POST'])
@app.route('/r/api/cleanup', methods=['POST'])  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ /r/
def cleanup():
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞
        now = time.time()
        removed = 0
        
        for filename in os.listdir(OUTPUT_DIR):
            filepath = os.path.join(OUTPUT_DIR, filename)
            if os.path.isfile(filepath):
                if now - os.path.getmtime(filepath) > 3600:  # 1 —á–∞—Å
                    os.remove(filepath)
                    removed += 1
        
        return jsonify({
            'message': f'–£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {removed}'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    try:
        init_service()
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    # –ó–∞–ø—É—Å–∫ Flask
    print(f"üåê –ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ http://localhost:3000")
    print(f"üìù –û—Ç–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ –∞–¥—Ä–µ—Å—É")
    print(f"   http://localhost:3000\n")
    
    app.run(
        host='0.0.0.0',
        port=3000,
        debug=False,
        threaded=True
    )
