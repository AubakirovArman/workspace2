#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π GPU –¥–ª—è Wav2Lip
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ batch_size, FP16, torch.compile
"""
import sys
import os
import time
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º modern-lipsync –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent / "modern-lipsync"))

import torch
import numpy as np
from service import LipsyncService


def get_gpu_memory():
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU"""
    if torch.cuda.is_available():
        return torch.cuda.max_memory_allocated() / 1024**3  # GB
    return 0


def benchmark_config(checkpoint_path: str, face_path: str, audio_path: str, 
                     batch_size: int, use_fp16: bool, use_compile: bool, 
                     num_runs: int = 3):
    """–ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    
    config_name = f"Batch={batch_size}, FP16={use_fp16}, Compile={use_compile}"
    print(f"\n{'='*70}")
    print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {config_name}")
    print(f"{'='*70}")
    
    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞
        init_start = time.time()
        service = LipsyncService(
            checkpoint_path=checkpoint_path,
            device='cuda',
            face_det_batch_size=16,
            wav2lip_batch_size=batch_size,
            use_fp16=use_fp16,
            use_compile=use_compile
        )
        init_time = time.time() - init_start
        
        # –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
        times = []
        for run in range(num_runs):
            print(f"\n  –ü—Ä–æ–≥–æ–Ω {run+1}/{num_runs}...")
            
            # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –ø—Ä–æ–≥–æ–Ω–æ–º
            service._static_cache.clear()
            service._video_cache.clear()
            
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            
            start = time.time()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞
            stats = service.process(
                face_path=face_path,
                audio_path=audio_path,
                output_path=f'/tmp/test_output_{batch_size}_{use_fp16}_{use_compile}_{run}.mp4',
                static=True,
                fps=25.0
            )
            
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            
            elapsed = time.time() - start
            times.append(elapsed)
            
            print(f"    –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {elapsed:.2f}s")
            print(f"    - –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ: {stats['load_video_time']:.2f}s")
            print(f"    - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ: {stats['process_audio_time']:.2f}s")
            print(f"    - –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü: {stats['face_detection_time']:.2f}s")
            print(f"    - –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏: {stats['inference_time']:.2f}s")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_time = np.mean(times)
        std_time = np.std(times)
        min_time = np.min(times)
        max_time = np.max(times)
        peak_memory = get_gpu_memory()
        
        print(f"\n  üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {init_time:.2f}s")
        print(f"    –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.2f}s ¬± {std_time:.2f}s")
        print(f"    –ú–∏–Ω/–ú–∞–∫—Å: {min_time:.2f}s / {max_time:.2f}s")
        print(f"    –ü–∏–∫–æ–≤–∞—è –ø–∞–º—è—Ç—å GPU: {peak_memory:.2f} GB")
        
        # –û—á–∏—Å—Ç–∫–∞
        del service
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return {
            'config': config_name,
            'batch_size': batch_size,
            'use_fp16': use_fp16,
            'use_compile': use_compile,
            'init_time': init_time,
            'avg_time': avg_time,
            'std_time': std_time,
            'min_time': min_time,
            'max_time': max_time,
            'peak_memory': peak_memory
        }
        
    except Exception as e:
        print(f"\n  ‚ùå –û—à–∏–±–∫–∞: {e}")
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        return None


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    if len(sys.argv) < 4:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python test_gpu_optimization.py <checkpoint> <face> <audio>")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print("  python test_gpu_optimization.py Wav2Lip-SD-GAN.pt avatar.jpg audio_40s.wav")
        sys.exit(1)
    
    checkpoint_path = sys.argv[1]
    face_path = sys.argv[2]
    audio_path = sys.argv[3]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤
    if not os.path.exists(checkpoint_path):
        print(f"‚ùå –ß–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {checkpoint_path}")
        sys.exit(1)
    if not os.path.exists(face_path):
        print(f"‚ùå –ê–≤–∞—Ç–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {face_path}")
        sys.exit(1)
    if not os.path.exists(audio_path):
        print(f"‚ùå –ê—É–¥–∏–æ –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
        sys.exit(1)
    
    print("\n" + "="*70)
    print("üöÄ –¢–ï–°–¢ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ô GPU –î–õ–Ø WAV2LIP")
    print("="*70)
    print(f"–ß–µ–∫–ø–æ–∏–Ω—Ç: {checkpoint_path}")
    print(f"–ê–≤–∞—Ç–∞—Ä: {face_path}")
    print(f"–ê—É–¥–∏–æ: {audio_path}")
    
    if torch.cuda.is_available():
        print(f"\nüéÆ GPU: {torch.cuda.get_device_name(0)}")
        print(f"   –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("\n‚ö†Ô∏è CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞! –¢–µ—Å—Ç—ã –±—É–¥—É—Ç –º–µ–¥–ª–µ–Ω–Ω—ã–º–∏.")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    configs = [
        # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (—Å—Ç–∞—Ä–∞—è)
        {'batch_size': 128, 'use_fp16': False, 'use_compile': False},
        
        # –¢–æ–ª—å–∫–æ —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π batch
        {'batch_size': 512, 'use_fp16': False, 'use_compile': False},
        
        # Batch + FP16
        {'batch_size': 512, 'use_fp16': True, 'use_compile': False},
        
        # Batch + FP16 + Compile (–ø–æ–ª–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
        {'batch_size': 512, 'use_fp16': True, 'use_compile': True},
        
        # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π batch (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–º—è—Ç—å)
        {'batch_size': 1024, 'use_fp16': True, 'use_compile': True},
    ]
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    results = []
    for config in configs:
        result = benchmark_config(
            checkpoint_path=checkpoint_path,
            face_path=face_path,
            audio_path=audio_path,
            num_runs=2,  # –ú–µ–Ω—å—à–µ –ø—Ä–æ–≥–æ–Ω–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏
            **config
        )
        if result:
            results.append(result)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
        print("\n  ‚è≥ –ü–∞—É–∑–∞ 5 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Ç–µ—Å—Ç–æ–º...")
        time.sleep(5)
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞
    print("\n" + "="*70)
    print("üìà –ò–¢–û–ì–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("="*70)
    
    if not results:
        print("‚ùå –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
    print(f"\n{'–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è':<50} {'–í—Ä–µ–º—è (s)':<15} {'–£—Å–∫–æ—Ä–µ–Ω–∏–µ':<12} {'–ü–∞–º—è—Ç—å (GB)':<12}")
    print("-" * 90)
    
    # –ë–∞–∑–æ–≤–æ–µ –≤—Ä–µ–º—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
    baseline_time = results[0]['avg_time']
    
    for result in results:
        config_str = f"B={result['batch_size']}, FP16={result['use_fp16']}, Comp={result['use_compile']}"
        time_str = f"{result['avg_time']:.2f} ¬± {result['std_time']:.2f}"
        speedup = baseline_time / result['avg_time']
        speedup_str = f"{speedup:.2f}x"
        memory_str = f"{result['peak_memory']:.2f}"
        
        print(f"{config_str:<50} {time_str:<15} {speedup_str:<12} {memory_str:<12}")
    
    # –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    best_result = min(results, key=lambda x: x['avg_time'])
    print("\n" + "="*70)
    print(f"üèÜ –õ–£–ß–®–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:")
    print(f"   Batch Size: {best_result['batch_size']}")
    print(f"   FP16: {best_result['use_fp16']}")
    print(f"   Compile: {best_result['use_compile']}")
    print(f"   –í—Ä–µ–º—è: {best_result['avg_time']:.2f}s")
    print(f"   –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {baseline_time / best_result['avg_time']:.2f}x")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
