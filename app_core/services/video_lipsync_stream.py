"""–ü–æ—Ç–æ–∫–æ–≤–∞—è lip-sync –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å –∫–æ–Ω–≤–µ–π–µ—Ä–æ–º decode‚Üíinference‚Üíencode.

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ H200: NVDEC –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, GPU –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞, libx264 –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è.
–ë–µ–∑ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ —Å–∫–ª–µ–π–∫–∏ ‚Äî –µ–¥–∏–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Ç –≤—Ö–æ–¥–∞ –¥–æ –≤—ã—Ö–æ–¥–∞.
"""
from __future__ import annotations

import json
import os
import shlex
import subprocess
import threading
import time
from queue import Queue
from typing import Optional

import cv2
import numpy as np
import torch


def ffprobe_video(video_path: str) -> tuple[int, int, float]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (width, height, fps) –¥–ª—è –≤–∏–¥–µ–æ."""
    cmd = f"ffprobe -v error -print_format json -show_streams {shlex.quote(video_path)}"
    out = subprocess.check_output(cmd, shell=True).decode("utf-8")
    info = json.loads(out)
    vstream = next((s for s in info.get('streams', []) if s.get('codec_type') == 'video'), None)
    if vstream is None:
        raise RuntimeError('–í–∏–¥–µ–æ –ø–æ—Ç–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω')
    
    w, h = int(vstream.get('width', 0)), int(vstream.get('height', 0))
    r = vstream.get('r_frame_rate', '30/1')
    try:
        num, den = map(int, r.split('/'))
        fps = num / den if den else 25.0
    except Exception:
        fps = 25.0
    return w, h, fps


def start_video_decoder(video_path: str, w: int, h: int, use_nvdec: bool = False) -> subprocess.Popen:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç ffmpeg –¥–µ–∫–æ–¥–µ—Ä –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤.
    
    Args:
        video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ
        w, h: —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–æ–≤
        use_nvdec: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–ø–ø–∞—Ä–∞—Ç–Ω–æ–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (H200 –∏–º–µ–µ—Ç 7x NVDEC)
    
    Returns:
        Popen –ø—Ä–æ—Ü–µ—Å—Å —Å stdout = raw RGB –∫–∞–¥—Ä—ã
    """
    cmd = ['ffmpeg', '-hide_banner', '-loglevel', 'error']
    
    if use_nvdec:
        # H200: NVDEC –¥–ª—è –∞–ø–ø–∞—Ä–∞—Ç–Ω–æ–≥–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        cmd.extend(['-hwaccel', 'cuda', '-hwaccel_output_format', 'cuda'])
    
    cmd.extend([
        '-i', video_path,
        '-f', 'rawvideo',
        '-pix_fmt', 'rgb24',
        '-vsync', '0',
        '-'
    ])
    
    return subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)


def start_video_encoder(
    output_path: str,
    audio_path: str,
    w: int,
    h: int,
    fps: float,
    encoder: str = 'libx264',
    crf: int = 20,
    preset: str = 'veryfast'
) -> subprocess.Popen:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç ffmpeg —ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤.
    
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ H200: libx264 –Ω–∞ CPU —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ CFR.
    
    Args:
        output_path: –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        audio_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ (WAV) –¥–ª—è –ø–æ–¥–º–µ—à–∏–≤–∞–Ω–∏—è
        w, h: —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–æ–≤
        fps: —á–∞—Å—Ç–æ—Ç–∞ –∫–∞–¥—Ä–æ–≤
        encoder: 'libx264' (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è H200) –∏–ª–∏ 'h264_nvenc'
        crf: –∫–∞—á–µ—Å—Ç–≤–æ (18-23, –º–µ–Ω—å—à–µ=–ª—É—á—à–µ)
        preset: 'ultrafast', 'veryfast', 'fast', 'medium'
    
    Returns:
        Popen –ø—Ä–æ—Ü–µ—Å—Å —Å stdin = raw RGB –∫–∞–¥—Ä—ã
    """
    keyint = int(2 * fps)  # GOP = 2 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π CFR
    
    if encoder == 'libx264':
        cmd = [
            'ffmpeg', '-hide_banner', '-loglevel', 'error',
            # –í—Ö–æ–¥–Ω–æ–π –≤–∏–¥–µ–æ –ø–æ—Ç–æ–∫ (raw RGB)
            '-f', 'rawvideo', '-pix_fmt', 'rgb24',
            '-s', f'{w}x{h}', '-r', str(fps), '-i', '-',
            # –ê—É–¥–∏–æ
            '-i', audio_path,
            # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ—Ç–æ–∫–æ–≤
            '-map', '0:v:0', '-map', '1:a:0',
            # –í–∏–¥–µ–æ –∫–æ–¥–µ–∫ (libx264 –Ω–∞ CPU)
            '-c:v', 'libx264',
            '-preset', preset,
            '-crf', str(crf),
            '-x264-params', f'keyint={keyint}:min-keyint={keyint}:scenecut=0:force-cfr=1',
            '-pix_fmt', 'yuv420p',
            # –ê—É–¥–∏–æ –∫–æ–¥–µ–∫
            '-c:a', 'aac', '-b:a', '192k', '-ar', '48000',
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
            '-movflags', '+faststart',
            '-shortest',
            output_path
        ]
    else:  # h264_nvenc (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –Ω–∞ H200 –æ–±—ã—á–Ω–æ –Ω–µ—Ç)
        cmd = [
            'ffmpeg', '-hide_banner', '-loglevel', 'error',
            '-f', 'rawvideo', '-pix_fmt', 'rgb24',
            '-s', f'{w}x{h}', '-r', str(fps), '-i', '-',
            '-i', audio_path,
            '-map', '0:v:0', '-map', '1:a:0',
            '-c:v', 'h264_nvenc',
            '-preset', 'p5',
            '-rc', 'vbr', '-cq', str(crf),
            '-pix_fmt', 'yuv420p',
            '-c:a', 'aac', '-b:a', '192k', '-ar', '48000',
            '-movflags', '+faststart',
            '-shortest',
            output_path
        ]
    
    return subprocess.Popen(cmd, stdin=subprocess.PIPE, stderr=subprocess.PIPE)


def process_video_lipsync_streaming(
    base_video_path: str,
    audio_path: str,
    output_path: str,
    lipsync_service,
    use_nvdec: bool = False,
    encoder: str = 'libx264',
    crf: int = 20,
    preset: str = 'veryfast',
    pads: tuple[int, int, int, int] = (0, 10, 0, 0),
    nosmooth: bool = False,
) -> dict:
    """–ü–æ—Ç–æ–∫–æ–≤–∞—è lip-sync –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –±–µ–∑ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: ffmpeg decode ‚Üí Queue ‚Üí GPU lip-sync ‚Üí Queue ‚Üí ffmpeg encode
    
    Args:
        base_video_path: –∏—Å—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ (–±–∞–∑–∞ –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞)
        audio_path: –∞—É–¥–∏–æ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –≥—É–± (WAV)
        output_path: –≤—ã—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ
        lipsync_service: —ç–∫–∑–µ–º–ø–ª—è—Ä LipsyncService —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
        use_nvdec: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å NVDEC (H200 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)
        encoder: 'libx264' –∏–ª–∏ 'h264_nvenc'
        crf: –∫–∞—á–µ—Å—Ç–≤–æ (18-23)
        preset: —Å–∫–æ—Ä–æ—Å—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        pads: –æ—Ç—Å—Ç—É–ø—ã –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü–∞
        nosmooth: –æ—Ç–∫–ª—é—á–∏—Ç—å —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
    
    Returns:
        dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    start_total = time.time()
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ
    w, h, fps = ffprobe_video(base_video_path)
    print(f"üìπ –í–∏–¥–µ–æ: {w}x{h} @ {fps:.2f} FPS")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∫–∞–¥—Ä—ã –≤–∏–¥–µ–æ (–¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –ø–µ—Ä–≤–æ–π –≤–µ—Ä—Å–∏–∏)
    # TODO: –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –º–æ–∂–Ω–æ —Å—Ç—Ä–∏–º–∏—Ç—å —á–µ—Ä–µ–∑ –æ—á–µ—Ä–µ–¥—å
    print("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–¥—Ä–æ–≤ –±–∞–∑–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ...")
    start = time.time()
    video_frames = _load_video_frames(base_video_path)
    load_time = time.time() - start
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(video_frames)} –∫–∞–¥—Ä–æ–≤ –∑–∞ {load_time:.2f}s")
    
    # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü –Ω–∞ –≤—Å–µ—Ö –∫–∞–¥—Ä–∞—Ö (–∫—ç—à–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)
    print("üë§ –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü...")
    start = time.time()
    face_det_results = lipsync_service.detect_faces(video_frames, pads, nosmooth)
    detect_time = time.time() - start
    print(f"‚úÖ –î–µ—Ç–µ–∫—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {detect_time:.2f}s")
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ -> –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã
    print("üéµ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ...")
    start = time.time()
    mel, mel_chunks, temp_wav = lipsync_service._process_audio(audio_path, fps)
    audio_time = time.time() - start
    print(f"‚úÖ –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {audio_time:.2f}s, —á–∞–Ω–∫–æ–≤: {len(mel_chunks)}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —ç–Ω–∫–æ–¥–µ—Ä
    print(f"üé¨ –ó–∞–ø—É—Å–∫ —ç–Ω–∫–æ–¥–µ—Ä–∞ ({encoder})...")
    encoder_proc = start_video_encoder(
        output_path, audio_path, w, h, fps,
        encoder=encoder, crf=crf, preset=preset
    )
    
    # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å + –∑–∞–ø–∏—Å—å –∫–∞–¥—Ä–æ–≤
    print("üé≠ Lip-sync –∏–Ω—Ñ–µ—Ä–µ–Ω—Å...")
    start = time.time()
    
    batch_size = lipsync_service.wav2lip_batch_size
    frames_processed = 0
    
    for i in range(0, len(mel_chunks), batch_size):
        batch_mel = mel_chunks[i:i + batch_size]
        img_batch, mel_batch, frames_batch, coords_batch = [], [], [], []
        
        for j, mel_window in enumerate(batch_mel):
            idx = (i + j) % len(video_frames)
            frame_to_save = video_frames[idx].copy()
            face, coords = face_det_results[idx]
            
            face_resized = cv2.resize(face, (lipsync_service.img_size, lipsync_service.img_size))
            
            img_batch.append(face_resized)
            mel_batch.append(mel_window)
            frames_batch.append(frame_to_save)
            coords_batch.append(coords)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –±–∞—Ç—á–∞ –¥–ª—è –º–æ–¥–µ–ª–∏
        img_batch_np = np.asarray(img_batch)
        mel_batch_np = np.asarray(mel_batch)
        
        img_masked = img_batch_np.copy()
        img_masked[:, lipsync_service.img_size // 2:] = 0
        
        img_batch_np = np.concatenate((img_masked, img_batch_np), axis=3) / 255.0
        mel_batch_np = np.reshape(
            mel_batch_np, [len(mel_batch_np), mel_batch_np.shape[1], mel_batch_np.shape[2], 1]
        )
        
        img_batch_tensor = torch.from_numpy(
            np.transpose(img_batch_np, (0, 3, 1, 2))
        ).float().to(lipsync_service.device)
        
        mel_batch_tensor = torch.from_numpy(
            np.transpose(mel_batch_np, (0, 3, 1, 2))
        ).float().to(lipsync_service.device)
        
        # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
        with torch.no_grad():
            pred = lipsync_service.model(mel_batch_tensor, img_batch_tensor)
        
        pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.0
        
        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∑–∞–ø–∏—Å—å –∫–∞–¥—Ä–æ–≤
        for predicted_patch, frame, coords in zip(pred, frames_batch, coords_batch):
            y1, y2, x1, x2 = coords
            frame_patch = predicted_patch.astype(np.uint8)
            frame_patch = cv2.resize(frame_patch, (x2 - x1, y2 - y1))
            frame[y1:y2, x1:x2] = frame_patch
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR -> RGB –¥–ª—è —ç–Ω–∫–æ–¥–µ—Ä–∞
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            encoder_proc.stdin.write(frame_rgb.tobytes())
            frames_processed += 1
    
    inference_time = time.time() - start
    print(f"‚úÖ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –∑–∞–≤–µ—Ä—à—ë–Ω: {frames_processed} –∫–∞–¥—Ä–æ–≤ –∑–∞ {inference_time:.2f}s")
    print(f"   ({frames_processed / inference_time:.1f} FPS)")
    
    # –ó–∞–≤–µ—Ä—à–∞–µ–º —ç–Ω–∫–æ–¥–µ—Ä
    encoder_proc.stdin.close()
    encoder_proc.wait()
    
    # –û—á–∏—Å—Ç–∫–∞ temp —Ñ–∞–π–ª–æ–≤
    if temp_wav and os.path.exists(temp_wav):
        try:
            os.remove(temp_wav)
        except OSError:
            pass
    
    total_time = time.time() - start_total
    
    stats = {
        'load_video_time': load_time,
        'face_detection_time': detect_time,
        'process_audio_time': audio_time,
        'inference_time': inference_time,
        'total_time': total_time,
        'frames_processed': frames_processed,
        'fps_achieved': frames_processed / inference_time if inference_time > 0 else 0,
        'video_resolution': f'{w}x{h}',
        'video_fps': fps,
        'encoder': encoder,
        'use_nvdec': use_nvdec,
    }
    
    print(f"\n‚úÖ –í–∏–¥–µ–æ –≥–æ—Ç–æ–≤–æ: {output_path}")
    print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f}s")
    
    return stats


def _load_video_frames(video_path: str) -> list[np.ndarray]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∫–∞–¥—Ä—ã –≤–∏–¥–µ–æ –≤ –ø–∞–º—è—Ç—å (BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV)."""
    cap = cv2.VideoCapture(video_path)
    frames = []
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)
    
    cap.release()
    return frames
