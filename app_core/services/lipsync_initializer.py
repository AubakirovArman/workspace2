"""Initialization logic for the preloaded lipsync service."""
from __future__ import annotations

import os
import time
from pathlib import Path
from typing import Optional, Tuple

import torch

from ..config import (
    AVATAR_FPS,
    AVATAR_IMAGE,
    AVATAR_VIDEO_PATH,
    AVATAR_PREVIEW_PATH,
    AVATAR_STATIC_MODE,
    CHECKPOINT_PATH_GAN,
    CHECKPOINT_PATH_NOGAN,
    MAX_GAN_MODELS,
    GAN_MODEL_INSTANCES,
    ENABLE_REALESRGAN,
    ENABLE_SEGMENTATION,
    ENABLE_SUPER_RESOLUTION,
    HD_MODULES_ROOT,
    REALESRGAN_OUTSCALE,
    REALESRGAN_PATH,
    SEGMENTATION_PATH_HD,
    SR_PATH_HD,
)
from ..state import set_state

from service import LipsyncService  # noqa: E402


_IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
_VIDEO_EXTENSIONS = {'.mp4', '.mov', '.avi', '.mkv', '.webm', '.m4v'}


def _is_video(path: str) -> bool:
    return Path(path).suffix.lower() in _VIDEO_EXTENSIONS


def _is_image(path: str) -> bool:
    return Path(path).suffix.lower() in _IMAGE_EXTENSIONS


def _resolve_realesrgan_path() -> Optional[str]:
    if not ENABLE_REALESRGAN:
        print("‚ÑπÔ∏è Real-ESRGAN –æ—Ç–∫–ª—é—á–µ–Ω (ENABLE_REALESRGAN=0).")
        return None
    if os.path.exists(REALESRGAN_PATH):
        print(f"‚úÖ Real-ESRGAN –≤–µ—Å–∞ –Ω–∞–π–¥–µ–Ω—ã: {REALESRGAN_PATH} (outscale={REALESRGAN_OUTSCALE})")
        return REALESRGAN_PATH
    print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≤–µ—Å–∞ Real-ESRGAN –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ({REALESRGAN_PATH}). –£–ª—É—á—à–µ–Ω–∏–µ –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–æ.")
    return None


def init_lipsync_service() -> Tuple[LipsyncService, Optional[LipsyncService], Optional[object]]:
    print("\n" + "=" * 60)
    print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Avatar Lipsync Service")
    print("=" * 60)

    if not os.path.exists(AVATAR_IMAGE):
        raise FileNotFoundError(f"–ê–≤–∞—Ç–∞—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {AVATAR_IMAGE}")
    if not os.path.exists(CHECKPOINT_PATH_GAN):
        raise FileNotFoundError(f"GAN –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {CHECKPOINT_PATH_GAN}")
    if not os.path.exists(CHECKPOINT_PATH_NOGAN):
        print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: NoGAN –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ({CHECKPOINT_PATH_NOGAN}). –°—Ç—Ä–∞–Ω–∏—Ü–∞ realtime2 –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
    realesrgan_available = _resolve_realesrgan_path()

    print(f"‚úÖ –ê–≤–∞—Ç–∞—Ä –Ω–∞–π–¥–µ–Ω: {AVATAR_IMAGE}")
    print(f"‚úÖ GAN –º–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞: {CHECKPOINT_PATH_GAN}")
    if os.path.exists(CHECKPOINT_PATH_NOGAN):
        print(f"‚úÖ NoGAN –º–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞: {CHECKPOINT_PATH_NOGAN}")

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    if device == 'cuda':
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True
        if hasattr(torch, 'set_float32_matmul_precision'):
            torch.set_float32_matmul_precision('high')

    use_hd_modules = ENABLE_SEGMENTATION or ENABLE_SUPER_RESOLUTION or ENABLE_REALESRGAN

    hd_modules_root: Optional[str] = None
    if use_hd_modules:
        if HD_MODULES_ROOT.exists():
            hd_modules_root = str(HD_MODULES_ROOT)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã –º–æ–¥—É–ª–∏ Wav2Lip-HD: {hd_modules_root}")
        else:
            print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ —Å –∫–æ–¥–æ–º Wav2Lip-HD –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {HD_MODULES_ROOT}")
    else:
        print("‚ÑπÔ∏è –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ HD –º–æ–¥—É–ª–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã (ENABLE_* —Ñ–ª–∞–≥–∏ = 0).")

    segmentation_path: Optional[str] = None
    if ENABLE_SEGMENTATION:
        if os.path.exists(SEGMENTATION_PATH_HD):
            segmentation_path = SEGMENTATION_PATH_HD
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω–∞: {SEGMENTATION_PATH_HD}")
        else:
            print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ñ–∞–π–ª —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω ({SEGMENTATION_PATH_HD}). –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Ç–æ–ª—å–∫–æ Wav2Lip –±–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.")
    else:
        print("‚ÑπÔ∏è –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞ (ENABLE_SEGMENTATION=0).")

    sr_path: Optional[str] = None
    if ENABLE_SUPER_RESOLUTION:
        if os.path.exists(SR_PATH_HD):
            sr_path = SR_PATH_HD
            print(f"‚úÖ –°—É–ø–µ—Ä—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ ESRGAN –≤–∫–ª—é—á–µ–Ω–æ: {SR_PATH_HD}")
        else:
            print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ñ–∞–π–ª —Å—É–ø–µ—Ä—Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω ({SR_PATH_HD}). –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ ESRGAN.")
    else:
        print("‚ÑπÔ∏è –°—É–ø–µ—Ä—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ (ENABLE_SUPER_RESOLUTION=0).")

    common_kwargs = dict(
        face_det_batch_size=16,
        wav2lip_batch_size=16,
        segmentation_path=segmentation_path,
        sr_path=sr_path,
        modules_root=hd_modules_root,
        realesrgan_path=realesrgan_available,
        realesrgan_outscale=REALESRGAN_OUTSCALE,
        use_fp16=True,
        use_compile=True,
    )

    total_instances = GAN_MODEL_INSTANCES
    if total_instances > MAX_GAN_MODELS:
        total_instances = MAX_GAN_MODELS

    if device == 'cuda':
        logical_gpu_count = torch.cuda.device_count()
        visible_devices = [f'cuda:{idx}' for idx in range(logical_gpu_count)]
        if not visible_devices:
            visible_devices = ['cuda:0']

        if len(visible_devices) >= total_instances:
            if len(visible_devices) > total_instances:
                print(
                    f"‚ÑπÔ∏è –ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {total_instances} –∏–∑ {len(visible_devices)} –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU –¥–ª—è GAN –º–æ–¥–µ–ª–µ–π."
                )
            gan_devices = visible_devices[:total_instances]
        else:
            print(
                f"‚ö†Ô∏è –ó–∞–ø—Ä–æ—à–µ–Ω–æ {total_instances} GAN –º–æ–¥–µ–ª–µ–π, –Ω–æ –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ {len(visible_devices)} GPU. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ."
            )
            gan_devices = [visible_devices[idx % len(visible_devices)] for idx in range(total_instances)]
    else:
        gan_devices = [device] * total_instances

    if not gan_devices:
        gan_devices = [device]
        total_instances = 1

    unique_devices = sorted(set(gan_devices), key=gan_devices.index)
    reuse_notice = " (–ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU)" if len(unique_devices) < len(gan_devices) else ""
    print(
        f"üß† –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∫–∞ {len(gan_devices)} GAN –º–æ–¥–µ–ª–µ–π –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞: {', '.join(gan_devices)}{reuse_notice}"
    )

    is_video_source = _is_video(AVATAR_IMAGE)
    use_static_cache = AVATAR_STATIC_MODE or not is_video_source
    if not AVATAR_STATIC_MODE and not is_video_source:
        print("‚ö†Ô∏è –ó–∞–ø—Ä–æ—à–µ–Ω –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º, –Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –≤–∏–¥–µ–æ. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞—Ç–∏—á–Ω—ã–π —Ä–µ–∂–∏–º.")

    if use_static_cache:
        print("üéØ –†–µ–∂–∏–º –∞–≤–∞—Ç–∞—Ä–∞: —Å—Ç–∞—Ç–∏—á–Ω—ã–π (–ø—Ä–µ–¥–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–∏—Ü–æ)")
    else:
        print("üéûÔ∏è –†–µ–∂–∏–º –∞–≤–∞—Ç–∞—Ä–∞: –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Å—ë –≤–∏–¥–µ–æ)")

    primary_device = gan_devices[0]
    print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ GAN –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç—å (device={primary_device})...")
    start = time.time()
    gan_service = LipsyncService(
        checkpoint_path=CHECKPOINT_PATH_GAN,
        device=primary_device,
        **common_kwargs
    )
    model_ready_time = time.time()
    print(f"‚úÖ GAN –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {model_ready_time - start:.2f}s")

    if use_static_cache:
        preload_start = time.time()
        gan_service.preload_static_face(
            face_path=AVATAR_IMAGE,
            fps=AVATAR_FPS,
            pads=(0, 50, 0, 0)
        )
        print(f"‚ö° –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞ (GAN) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - preload_start:.2f}s")
    else:
        preload_start = time.time()
        gan_service.preload_video_cache(
            face_path=AVATAR_IMAGE,
            fps=AVATAR_FPS,
            pads=(0, 50, 0, 0)
        )
        print(f"‚ö° –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ (GAN) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - preload_start:.2f}s")

    if _is_video(AVATAR_VIDEO_PATH) and os.path.exists(AVATAR_VIDEO_PATH):
        need_dynamic_preload = use_static_cache or AVATAR_VIDEO_PATH != AVATAR_IMAGE
        if need_dynamic_preload:
            try:
                dynamic_start = time.time()
                gan_service.preload_video_cache(
                    face_path=AVATAR_VIDEO_PATH,
                    fps=AVATAR_FPS,
                    pads=(0, 50, 0, 0)
                )
                print(f"‚ö° –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ ({AVATAR_VIDEO_PATH}) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - dynamic_start:.2f}s")
            except Exception as dynamic_error:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–≤–∞—Ç–∞—Ä {AVATAR_VIDEO_PATH}: {dynamic_error}")

    nogan_service: Optional[LipsyncService] = None

    additional_gan_services = []
    for idx, device_name in enumerate(gan_devices[1:], start=2):
        print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ GAN –º–æ–¥–µ–ª–∏ #{idx} (device={device_name})...")
        start = time.time()
        gan_extra = LipsyncService(
            checkpoint_path=CHECKPOINT_PATH_GAN,
            device=device_name,
            **common_kwargs
        )
        model_ready_time = time.time()
        print(f"‚úÖ GAN-{idx} –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {model_ready_time - start:.2f}s")

        if use_static_cache:
            preload_start = time.time()
            gan_extra.preload_static_face(
                face_path=AVATAR_IMAGE,
                fps=AVATAR_FPS,
                pads=(0, 50, 0, 0)
            )
            print(f"‚ö° –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞ (GAN-{idx}) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - preload_start:.2f}s")
        else:
            preload_start = time.time()
            gan_extra.preload_video_cache(
                face_path=AVATAR_IMAGE,
                fps=AVATAR_FPS,
                pads=(0, 50, 0, 0)
            )
            print(f"‚ö° –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ (GAN-{idx}) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - preload_start:.2f}s")

        if _is_video(AVATAR_VIDEO_PATH) and os.path.exists(AVATAR_VIDEO_PATH):
            need_dynamic_preload_extra = use_static_cache or AVATAR_VIDEO_PATH != AVATAR_IMAGE
            if need_dynamic_preload_extra:
                try:
                    dynamic_start = time.time()
                    gan_extra.preload_video_cache(
                        face_path=AVATAR_VIDEO_PATH,
                        fps=AVATAR_FPS,
                        pads=(0, 50, 0, 0)
                    )
                    print(f"‚ö° –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ (GAN-{idx}) –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - dynamic_start:.2f}s")
                except Exception as dynamic_error:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–≤–∞—Ç–∞—Ä {AVATAR_VIDEO_PATH} –¥–ª—è GAN-{idx}: {dynamic_error}")

        additional_gan_services.append(gan_extra)

    print("\nüñºÔ∏è  –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞...")
    avatar_preloaded = None
    try:
        import cv2  # Local import to avoid unnecessary import during unit tests

        preview_saved = False
        if _is_video(AVATAR_IMAGE):
            capture = cv2.VideoCapture(AVATAR_IMAGE)
            success, frame = capture.read()
            capture.release()
            if success and frame is not None:
                avatar_preloaded = frame
                print(f"‚úÖ –ü–µ—Ä–≤—ã–π –∫–∞–¥—Ä –≤–∏–¥–µ–æ-–∞–≤–∞—Ç–∞—Ä–∞: {avatar_preloaded.shape}")
                preview_saved = cv2.imwrite(AVATAR_PREVIEW_PATH, frame)
            else:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å—á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä –≤–∏–¥–µ–æ-–∞–≤–∞—Ç–∞—Ä–∞")
        else:
            avatar_preloaded = cv2.imread(AVATAR_IMAGE)
            if avatar_preloaded is not None:
                print(f"‚úÖ –ê–≤–∞—Ç–∞—Ä –∑–∞–≥—Ä—É–∂–µ–Ω: {avatar_preloaded.shape}")
                preview_saved = cv2.imwrite(AVATAR_PREVIEW_PATH, avatar_preloaded)
            else:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∏—Ç—å –∞–≤–∞—Ç–∞—Ä –≤ –ø–∞–º—è—Ç—å")

        if preview_saved:
            print(f"üñºÔ∏è  –ü—Ä–µ–≤—å—é –∞–≤–∞—Ç–∞—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {AVATAR_PREVIEW_PATH}")
        elif avatar_preloaded is not None:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–≤—å—é –∞–≤–∞—Ç–∞—Ä–∞")
    except ImportError:
        print("‚ö†Ô∏è OpenCV –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞.")

    total_gan_models = 1 + len(additional_gan_services)

    print("\n" + "=" * 60)
    print("‚úÖ –°–µ—Ä–≤–∏—Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    print(f"   üöÄ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_gan_models}x GAN" + (" + 1x NoGAN" if nogan_service else ""))
    print("=" * 60 + "\n")

    set_state(gan_service, nogan_service, avatar_preloaded, use_static_cache, *additional_gan_services)
    return gan_service, nogan_service, avatar_preloaded
