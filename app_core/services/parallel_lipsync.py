"""
Parallel Lipsync Processing
–£—Å–∫–æ—Ä–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–∞ –¥–≤—É—Ö –º–æ–¥–µ–ª—è—Ö
"""
from __future__ import annotations

import os
import tempfile
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import List, Optional, Tuple

import cv2
import numpy as np
from pydub import AudioSegment


def split_audio_file(audio_path: str, num_chunks: int = 2) -> List[Tuple[str, float, float]]:
    """
    –†–∞–∑–±–∏—Ç—å –∞—É–¥–∏–æ –Ω–∞ N —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    
    Args:
        audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        num_chunks: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2 –¥–ª—è –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π)
        
    Returns:
        List[(chunk_path, start_time, end_time)]
    """
    audio = AudioSegment.from_file(audio_path)
    duration_ms = len(audio)
    chunk_duration = duration_ms / num_chunks
    
    chunks = []
    temp_dir = tempfile.mkdtemp(prefix="audio_chunks_")
    
    for i in range(num_chunks):
        start_ms = int(i * chunk_duration)
        end_ms = int((i + 1) * chunk_duration) if i < num_chunks - 1 else duration_ms
        
        chunk = audio[start_ms:end_ms]
        chunk_path = os.path.join(temp_dir, f"chunk_{i:03d}.wav")
        chunk.export(chunk_path, format="wav")
        
        chunks.append((chunk_path, start_ms / 1000.0, end_ms / 1000.0))
    
    return chunks


def process_chunk_with_service(
    service,
    audio_chunk_path: str,
    chunk_index: int,
    use_cached: bool = True
) -> Tuple[int, str]:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω —á–∞–Ω–∫ –∞—É–¥–∏–æ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª—å—é
    
    Args:
        service: LipsyncService (GAN –∏–ª–∏ NOGAN)
        audio_chunk_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —á–∞–Ω–∫—É
        chunk_index: –ò–Ω–¥–µ–∫—Å —á–∞–Ω–∫–∞ (–¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏)
        use_cached: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ
        
    Returns:
        (chunk_index, output_video_path)
    """
    temp_output = tempfile.mktemp(suffix=f"_chunk_{chunk_index:03d}.mp4")
    
    if use_cached:
        service.process_with_preloaded(
            audio_path=audio_chunk_path,
            output_path=temp_output
        )
    else:
        # –î–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∂–∏–º–∞ –Ω—É–∂–µ–Ω face_path
        raise NotImplementedError("–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
    
    return chunk_index, temp_output


def merge_video_chunks(chunk_paths: List[str], output_path: str, fps: int = 25) -> None:
    """
    –°–∫–ª–µ–∏—Ç—å –≤–∏–¥–µ–æ —á–∞–Ω–∫–∏ –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
    
    Args:
        chunk_paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –≤–∏–¥–µ–æ —á–∞–Ω–∫–∞–º (–≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ!)
        output_path: –ü—É—Ç—å –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        fps: FPS —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ
    """
    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –¥–ª—è ffmpeg concat
    concat_file = tempfile.mktemp(suffix=".txt")
    
    with open(concat_file, 'w') as f:
        for chunk_path in chunk_paths:
            # –§–æ—Ä–º–∞—Ç –¥–ª—è ffmpeg concat demuxer
            f.write(f"file '{chunk_path}'\n")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ffmpeg –¥–ª—è —Å–∫–ª–µ–π–∫–∏
    import subprocess
    cmd = [
        'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
        '-i', concat_file,
        '-c', 'copy',  # –ö–æ–ø–∏—Ä—É–µ–º –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è (–±—ã—Å—Ç—Ä–æ!)
        output_path
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    os.unlink(concat_file)
    
    if result.returncode != 0:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ —Å–∫–ª–µ–π–∫–∏ –≤–∏–¥–µ–æ: {result.stderr}")


def parallel_lipsync_process(
    gan_service,
    nogan_service,
    audio_path: str,
    output_path: str,
    num_workers: int = 2,
    fps: int = 25,
    use_cached: bool = True,
    gan2_service=None,
    gan3_service=None,
    use_only_gan: bool = False
) -> dict:
    """
    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª—è—Ö
    
    Args:
        gan_service: GAN LipsyncService #1
        nogan_service: NOGAN LipsyncService
        audio_path: –ü—É—Ç—å –∫ –ø–æ–ª–Ω–æ–º—É –∞—É–¥–∏–æ
        output_path: –ü—É—Ç—å –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤ (2-3)
        fps: FPS —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        use_cached: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ
        gan2_service: –í—Ç–æ—Ä–æ–π —ç–∫–∑–µ–º–ø–ª—è—Ä GAN (–¥–ª—è 3 –º–æ–¥–µ–ª–µ–π)
        gan3_service: –¢—Ä–µ—Ç–∏–π —ç–∫–∑–µ–º–ø–ª—è—Ä GAN (–¥–ª—è 3 –º–æ–¥–µ–ª–µ–π)
        use_only_gan: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ GAN –º–æ–¥–µ–ª–∏ (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å NOGAN)
        
    Returns:
        dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    start_time = time.time()
    
    # 1. –†–∞–∑–±–∏—Ç—å –∞—É–¥–∏–æ –Ω–∞ —á–∞–Ω–∫–∏
    print(f"üì¶ –†–∞–∑–±–∏–≤–∞–µ–º –∞—É–¥–∏–æ –Ω–∞ {num_workers} —á–∞—Å—Ç–µ–π...")
    split_start = time.time()
    audio_chunks = split_audio_file(audio_path, num_chunks=num_workers)
    split_time = time.time() - split_start
    print(f"‚úÖ –ê—É–¥–∏–æ —Ä–∞–∑–±–∏—Ç–æ –∑–∞ {split_time:.2f}s")
    
    # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–ø–∏—Å–∫–∞ —Å–µ—Ä–≤–∏—Å–æ–≤
    if use_only_gan:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ GAN –º–æ–¥–µ–ª–∏
        available_services = [gan_service]
        if gan2_service:
            available_services.append(gan2_service)
        if gan3_service:
            available_services.append(gan3_service)
        services = available_services
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º GAN + NOGAN (—Å—Ç–∞—Ä–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
        services = [gan_service, nogan_service] if num_workers == 2 else [gan_service] * num_workers
    
    # 3. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ {len(services)} –º–æ–¥–µ–ª—è—Ö...")
    process_start = time.time()
    
    chunk_results = {}
    
    with ThreadPoolExecutor(max_workers=len(services)) as executor:
        futures = []
        
        for i, (chunk_path, start_t, end_t) in enumerate(audio_chunks):
            service = services[i % len(services)]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –º–æ–¥–µ–ª–∏
            if service == gan_service:
                service_name = "GAN-1"
            elif gan2_service and service == gan2_service:
                service_name = "GAN-2"
            elif gan3_service and service == gan3_service:
                service_name = "GAN-3"
            elif service == nogan_service:
                service_name = "NOGAN"
            else:
                service_name = "GAN"
            
            print(f"   - –ß–∞–Ω–∫ {i}: {start_t:.2f}s-{end_t:.2f}s ‚Üí {service_name}")
            
            future = executor.submit(
                process_chunk_with_service,
                service,
                chunk_path,
                i,
                use_cached
            )
            futures.append(future)
        
        # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        for future in as_completed(futures):
            chunk_idx, video_path = future.result()
            chunk_results[chunk_idx] = video_path
            print(f"   ‚úÖ –ß–∞–Ω–∫ {chunk_idx} –≥–æ—Ç–æ–≤")
    
    process_time = time.time() - process_start
    print(f"‚úÖ –í—Å–µ —á–∞–Ω–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∑–∞ {process_time:.2f}s")
    
    # 3. –°–∫–ª–µ–∏—Ç—å –≤–∏–¥–µ–æ —á–∞–Ω–∫–∏
    print("üé¨ –°–∫–ª–µ–∏–≤–∞–µ–º –≤–∏–¥–µ–æ —á–∞–Ω–∫–∏...")
    merge_start = time.time()
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É
    sorted_chunks = [chunk_results[i] for i in sorted(chunk_results.keys())]
    merge_video_chunks(sorted_chunks, output_path, fps)
    
    merge_time = time.time() - merge_start
    print(f"‚úÖ –í–∏–¥–µ–æ —Å–∫–ª–µ–µ–Ω–æ –∑–∞ {merge_time:.2f}s")
    
    # 4. –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    print("üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    for chunk_path, _, _ in audio_chunks:
        try:
            os.unlink(chunk_path)
            # –£–¥–∞–ª—è–µ–º —Ç–∞–∫–∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —á–∞–Ω–∫–æ–≤
            chunk_dir = os.path.dirname(chunk_path)
            if os.path.exists(chunk_dir):
                os.rmdir(chunk_dir)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {chunk_path}: {e}")
    
    for video_path in chunk_results.values():
        try:
            os.unlink(video_path)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {video_path}: {e}")
    
    total_time = time.time() - start_time
    
    return {
        "total_time": total_time,
        "split_time": split_time,
        "process_time": process_time,
        "merge_time": merge_time,
        "num_chunks": len(audio_chunks),
        "speedup": "~1.5-2x vs sequential"
    }


def estimate_optimal_chunks(audio_duration_seconds: float, num_models: int = 2) -> int:
    """
    –û—Ü–µ–Ω–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    
    Args:
        audio_duration_seconds: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        num_models: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        
    Returns:
        –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
    """
    # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞—É–¥–∏–æ (< 10s) –Ω–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª–∞ —Ä–∞–∑–±–∏–≤–∞—Ç—å
    if audio_duration_seconds < 10:
        return 1
    
    # –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö (10-30s) - 2 —á–∞–Ω–∫–∞
    if audio_duration_seconds < 30:
        return min(2, num_models)
    
    # –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö - –º–æ–∂–Ω–æ –±–æ–ª—å—à–µ, –Ω–æ –Ω–µ –±–æ–ª–µ–µ num_models * 2
    # (–∏–Ω–∞—á–µ overhead –æ—Ç —Å–∫–ª–µ–π–∫–∏ –ø—Ä–µ–≤—ã—Å–∏—Ç –≤—ã–∏–≥—Ä—ã—à)
    optimal = min(
        int(audio_duration_seconds / 15),  # –ö–∞–∂–¥—ã–π —á–∞–Ω–∫ ~15s
        num_models * 2
    )
    
    return max(2, optimal)
